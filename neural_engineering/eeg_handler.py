import os
import numpy as np
import pandas as pd
from scipy.signal import butter, lfilter, resample  # resample ì¶”ê°€
from datetime import datetime

# --- [ê·¸ë˜í”„ ì„¤ì •] ---
import matplotlib
matplotlib.use('Agg') # í™”ë©´ í‘œì‹œ ì—†ì´ íŒŒì¼ ì €ì¥ ì „ìš© ëª¨ë“œ
import matplotlib.pyplot as plt

class SignalProcessor:
    def __init__(self, fs=256):
        self.fs = fs
    def butter_bandpass_filter(self, data, lowcut, highcut, order=2):
        nyq = 0.5 * self.fs
        low = lowcut / nyq
        high = highcut / nyq
        b, a = butter(order, [low, high], btype="band")
        y = lfilter(b, a, data)
        return y
    def get_power(self, data): return data ** 2
    def moving_average(self, data, window_sec=1.0):
        window_size = int(window_sec * self.fs)
        return np.convolve(data, np.ones(window_size)/window_size, mode='same')

def get_latest_rawdata_path(base_path="C:/MAVE_RawData"):
    # 1ìˆœìœ„: Cë“œë¼ì´ë¸Œ ê²½ë¡œ í™•ì¸
    if os.path.exists(base_path):
        try:
            all_folders = [os.path.join(base_path, d) for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]
            if all_folders:
                latest_folder_path = max(all_folders, key=os.path.getctime)
                target_file = os.path.join(latest_folder_path, "Rawdata.txt")
                if os.path.exists(target_file): return target_file
        except: pass
    
    # 2ìˆœìœ„: í”„ë¡œì íŠ¸ í´ë” ë‚´ íŒŒì¼ í™•ì¸
    local_file = "Rawdata.txt"
    if os.path.exists(local_file):
        return os.path.abspath(local_file)
    return None

# âœ… [í•µì‹¬ ì¶”ê°€] ë°ì´í„° ë¦¬ìƒ˜í”Œë§ í•¨ìˆ˜
def force_resample_data(df, target_fs=256, expected_duration_sec=180):
    """
    ë°ì´í„°ê°€ ë¶€ì¡±í•  ê²½ìš°, ì˜ˆìƒ ì‹œê°„(180ì´ˆ)ê³¼ ëª©í‘œ ì£¼íŒŒìˆ˜(256Hz)ì— ë§ì¶°
    ë°ì´í„° ê°œìˆ˜ë¥¼ ê°•ì œë¡œ ëŠ˜ë¦½ë‹ˆë‹¤ (ì„ í˜• ë³´ê°„).
    """
    current_len = len(df)
    target_len = int(target_fs * expected_duration_sec) # 256 * 180 = 46080ê°œ
    # ì˜¤ì°¨ ë²”ìœ„ 10% ì´ë‚´ë©´ êµ³ì´ ë¦¬ìƒ˜í”Œë§ ì•ˆ í•¨ (ì •ìƒ ë°ì´í„°ë¡œ ê°„ì£¼)
    if abs(current_len - target_len) / target_len < 0.1:
        return df
    print(f"âš ï¸ ë°ì´í„° ê¸¸ì´ ë³´ì • ì‹¤í–‰: {current_len}í–‰ -> {target_len}í–‰ (ëª©í‘œ: {expected_duration_sec}ì´ˆ)")
    
    # ë¦¬ìƒ˜í”Œë§ ìˆ˜í–‰ (scipy.signal.resample ì‚¬ìš©)
    # ì£¼ì˜: resampleì€ Fourier ë°©ì‹ì´ë¼ ë°ì´í„°ê°€ íŠ€ëŠ” í˜„ìƒì´ ìˆì„ ìˆ˜ ìˆì–´, 
    # ì—¬ê¸°ì„œëŠ” ì•ˆì „í•˜ê²Œ Pandasì˜ ì„ í˜• ë³´ê°„(Linear Interpolation)ì„ ê¶Œì¥í•©ë‹ˆë‹¤.
    
    # 1. ê¸°ì¡´ ì¸ë±ìŠ¤ë¥¼ ì‹œê°„ ì¶•(0 ~ 1)ìœ¼ë¡œ ì •ê·œí™”
    old_indices = np.linspace(0, 1, current_len)
    new_indices = np.linspace(0, 1, target_len)
    
    # 2. ìƒˆë¡œìš´ DataFrame ìƒì„±
    new_df = pd.DataFrame()
    
    # 3. ê° ì»¬ëŸ¼ë³„ë¡œ ë³´ê°„(Interpolation) ìˆ˜í–‰
    for col in df.columns:
        if pd.api.types.is_numeric_dtype(df[col]):
            # np.interp(ìƒˆë¡œìš´x, ê¸°ì¡´x, ê¸°ì¡´y) -> ì„ í˜• ë³´ê°„
            new_df[col] = np.interp(new_indices, old_indices, df[col].values)
        else:
            # ìˆ«ìê°€ ì•„ë‹Œ ì»¬ëŸ¼(í˜¹ì‹œ ìˆë‹¤ë©´)ì€ ë‹¨ìˆœ ë³µì‚¬ ë¶ˆê°€í•˜ë¯€ë¡œ ì²˜ë¦¬ ì œì™¸
            pass
            
    return new_df

def calculate_concentration_index(processor, raw_signal):
    epsilon = 1e-10
    theta_wave = processor.butter_bandpass_filter(raw_signal, 4.0, 8.0)
    alpha_wave = processor.butter_bandpass_filter(raw_signal, 8.0, 13.0)
    beta_wave = processor.butter_bandpass_filter(raw_signal, 13.0, 30.0)
    
    theta_power = processor.moving_average(processor.get_power(theta_wave))
    alpha_power = processor.moving_average(processor.get_power(alpha_wave))
    beta_power = processor.moving_average(processor.get_power(beta_wave))
    
    ba_ratio = beta_power / (alpha_power + epsilon)
    bt_ratio = beta_power / (theta_power + epsilon)
    return (ba_ratio + bt_ratio) / 2.0

def save_analysis_log(log_lines):
    try:
        with open("analysis_log.txt", "w", encoding="utf-8") as f:
            f.write("\n".join(log_lines))
    except: pass

# ìˆ˜ì •ë¨: ì „ì²´ ë°ì´í„°ë¥¼ ë°›ì•„ì„œ Baseline êµ¬ë¶„ì„ ì„ ê·¸ì–´ì£¼ëŠ” í•¨ìˆ˜
def save_z_score_plot(full_z_fp1, full_z_fp2, threshold, ceiling, baseline_sec, fs=256):
    try:
        plt.close('all')
        
        # ì „ì²´ ì‹œê°„ì¶• ìƒì„±
        total_seconds = len(full_z_fp1) / fs
        time_axis = np.linspace(0, total_seconds, len(full_z_fp1))
        
        plt.figure(figsize=(10, 5))
        
        # ì „ì²´ ë°ì´í„° ê·¸ë¦¬ê¸°
        plt.plot(time_axis, full_z_fp1, label='Fp1 Z-Score', color='blue', alpha=0.6, linewidth=1)
        plt.plot(time_axis, full_z_fp2, label='Fp2 Z-Score', color='orange', alpha=0.6, linewidth=1)
        
        # ê¸°ì¤€ì„  ê·¸ë¦¬ê¸°
        plt.axhline(y=threshold, color='green', linestyle='--', label=f'Concentration Threshold ({threshold})')
        
        #  Baseline(30ì´ˆ) êµ¬ë¶„ì„  ì¶”ê°€ (ë¹¨ê°„ ì ì„ )
        plt.axvline(x=baseline_sec, color='red', linestyle=':', linewidth=2, label='End of Baseline (30s)')
        
        # ê·¸ë˜í”„ ê¾¸ë¯¸ê¸°
        plt.title(f"Full Z-Score Flow (Total: {total_seconds:.1f}s)")
        plt.xlabel("Time (seconds)")
        plt.ylabel("Z-Score (rel. to Baseline)")
        plt.legend(loc='upper right')
        plt.grid(True, alpha=0.3)
        plt.ylim(bottom=-2, top=min(ceiling + 1, 10)) # yì¶• ë²”ìœ„ ì•ˆì •í™”

        # ì €ì¥ (ì ˆëŒ€ ê²½ë¡œ)
        current_dir = os.path.dirname(os.path.abspath(__file__))
        project_dir = os.path.dirname(current_dir)
        save_path = os.path.join(project_dir, "z_score_graph.png")
        
        plt.savefig(save_path)
        print(f"ğŸ“Š ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ: {save_path}")
        plt.close()
    except Exception as e:
        print(f"ğŸš¨ ê·¸ë˜í”„ ì €ì¥ ì‹¤íŒ¨: {e}")

def analyze_concentration_intervals(file_path, baseline_sec=30.0, z_threshold=0.7, z_ceiling=4.0):
    log_buffer = []
    print(f"ğŸ” ë¶„ì„ ì‹œì‘: {file_path}")
    
    try:
        try:
            df = pd.read_csv(file_path, delimiter="\t", encoding='cp949')
        except:
            df = pd.read_csv(file_path, delimiter="\t", encoding='utf-8')

        if df.empty: return []

        # ============================================================
        # [ìˆ˜ì • í¬ì¸íŠ¸] ë°ì´í„° ë¡œë“œ ì§í›„ ë¦¬ìƒ˜í”Œë§ ìˆ˜í–‰
        # ì˜ìƒ ê¸¸ì´ê°€ 3ë¶„(180ì´ˆ)ì´ë¼ê³  ê°€ì •í•©ë‹ˆë‹¤. 
        # ë§Œì•½ ì˜ìƒë§ˆë‹¤ ê¸¸ì´ê°€ ë‹¤ë¥´ë‹¤ë©´ ì´ ê°’ì„ ì¸ìë¡œ ë°›ì•„ì•¼ í•©ë‹ˆë‹¤.
        VIDEO_DURATION_SEC = 196     # ì˜ìƒ  ê¸¸ì´ì— ë”°ë¼ +30ì´ˆë¥¼ ë”í•´ì„œ ê³„ì‚°ì„ í•´ì•¼í•¨. í˜„ì¬ ì˜ìƒ ê¸¸ì´ëŠ” 2ë¶„ 46ì´ˆ. ê²€ì€ í™”ë©´ 30ì´ˆ
        df = force_resample_data(df, target_fs=256, expected_duration_sec=VIDEO_DURATION_SEC)
        # ============================================================
        fs = 256
        processor = SignalProcessor(fs)
        
        col_fp1 = next((c for c in df.columns if 'Fp1' in c), df.columns[1])
        col_fp2 = next((c for c in df.columns if 'Fp2' in c), df.columns[2])

        signal_fp1 = df[col_fp1].values
        signal_fp2 = df[col_fp2].values
        
        # ì „ì²´ ê¸¸ì´ì— ëŒ€í•œ ì§€í‘œ ê³„ì‚°
        idx_fp1 = calculate_concentration_index(processor, signal_fp1)
        idx_fp2 = calculate_concentration_index(processor, signal_fp2)
        
        base_samples = int(baseline_sec * fs)
        
        # ë°ì´í„°ê°€ ë„ˆë¬´ ì§§ì•„ë„ ì¼ë‹¨ ì²˜ë¦¬ëŠ” ì‹œë„
        if len(idx_fp1) <= base_samples:
            print(f"âš ï¸ ê²½ê³ : ë°ì´í„° ê¸¸ì´({len(idx_fp1)/fs:.1f}ì´ˆ)ê°€ Baseline({baseline_sec}ì´ˆ)ë³´ë‹¤ ì§§ìŠµë‹ˆë‹¤.")
            # ì§§ì•„ë„ ì—ëŸ¬ ì•ˆ ë‚˜ê²Œ ê°•ì œ ì„¤ì •
            base_fp1 = idx_fp1
            base_fp2 = idx_fp2
        else:
            base_fp1 = idx_fp1[:base_samples]
            base_fp2 = idx_fp2[:base_samples]
        
        # Z-Score ë³€í™˜
        std_fp1 = np.std(base_fp1) if np.std(base_fp1) > 1e-10 else 1.0
        std_fp2 = np.std(base_fp2) if np.std(base_fp2) > 1e-10 else 1.0
        
        z_fp1 = (idx_fp1 - np.mean(base_fp1)) / std_fp1
        z_fp2 = (idx_fp2 - np.mean(base_fp2)) / std_fp2
        
        # [í•µì‹¬ ìˆ˜ì • 1] ë¶„ì„ ê²°ê³¼ì™€ ìƒê´€ì—†ì´ ì „ì²´ ê·¸ë˜í”„ë¥¼ ë¬´ì¡°ê±´ ê·¸ë¦¼
        # (ì˜ë¦° ë°ì´í„°ê°€ ì•„ë‹Œ 'z_fp1' ì „ì²´ë¥¼ ë„˜ê¹€)
        save_z_score_plot(z_fp1, z_fp2, z_threshold, z_ceiling, baseline_sec, fs)

        # ì‹¤ì œ ë¶„ì„ (30ì´ˆ ì´í›„ë¶€í„°)
        if len(z_fp1) > base_samples:
            task_z_fp1 = z_fp1[base_samples:]
            task_z_fp2 = z_fp2[base_samples:]
        else:
            print("ğŸ›‘ Baseline ì´í›„ ë°ì´í„°ê°€ ì—†ì–´ êµ¬ê°„ ë¶„ì„ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return []

        # êµ¬ê°„ ê²€ì¶œ ë¡œì§
        is_active = ((task_z_fp1 > z_threshold) | (task_z_fp2 > z_threshold))
        
        intervals = []
        start = None
        
        # iëŠ” task ì‹œì‘ ì‹œì (0ì´ˆ) ê¸°ì¤€ì„. ë‚˜ì¤‘ì— baseline_secë¥¼ ë”í•´ì¤˜ì•¼ ì‹¤ì œ ì‹œê°„.
        for i, active in enumerate(is_active):
            curr_task_time = i / fs
            if active and start is None:
                start = curr_task_time
            elif not active and start is not None:
                if curr_task_time - start >= 3.0: 
                    # ì‹¤ì œ ì˜ìƒ ì‹œê°„ = task ì‹œê°„ + 30ì´ˆ
                    intervals.append((start + baseline_sec, curr_task_time + baseline_sec))
                start = None
                
        if start is not None:
            end_task_time = len(is_active)/fs
            if end_task_time - start >= 3.0:
                 intervals.append((start + baseline_sec, end_task_time + baseline_sec))

        # [í•µì‹¬ ìˆ˜ì • 2] êµ¬ê°„ì´ ì—†ì–´ë„ ì—ëŸ¬ ë©”ì‹œì§€ ëŒ€ì‹  ë¡œê·¸ë§Œ ë‚¨ê¸°ê³  ì¢…ë£Œ
        if not intervals:
            save_analysis_log(["ì§‘ì¤‘ êµ¬ê°„ ì—†ìŒ (ê·¸ë˜í”„ í™•ì¸ ìš”ë§)"])
            print("ğŸ’¡ ì§‘ì¤‘ êµ¬ê°„ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê·¸ë˜í”„ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì „ì²´ ê¸¸ì´ì˜ ì¼ë¶€ë¥¼ ê°•ì œë¡œ ë°˜í™˜í•˜ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ
            # total_len = len(z_fp1)/fs
            # return [(total_len*0.4, total_len*0.6)] 
            return []

        return intervals

    except Exception as e:
        print(f"ğŸš¨ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return []

def load_timestamp_durations_from_file(file_path=None, ignored=None):
    # ìˆ˜ì •ëœ ë¡œì§: ì¸ìë¡œ ë°›ì€ file_pathê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ìš°ì„  ì‚¬ìš©
    if file_path and os.path.exists(file_path):
        target_path = file_path
    else:
        # ì—†ìœ¼ë©´ ê¸°ì¡´ì²˜ëŸ¼ ìë™ íƒìƒ‰
        target_path = get_latest_rawdata_path()
    
    # ì—¬ê¸°ì„œ ê¸°ì¤€ê°’(Threshold)ì„ ì¡°ì ˆí•˜ì„¸ìš” (í˜„ì¬ 0.7)
    FIXED_THRESHOLD = 0.7 

    if target_path:
        print(f"ğŸ“‚ íŒŒì¼ ë¡œë“œ ë° ë¶„ì„ ì‹œì‘: {target_path}")
        # analyze_concentration_intervals í•¨ìˆ˜ëŠ” ì „ì²´ ê²½ë¡œ(íŒŒì¼ëª… í¬í•¨)ë¥¼ í•„ìš”ë¡œ í•¨
        return analyze_concentration_intervals(target_path, z_threshold=FIXED_THRESHOLD)
    else:
        print("ğŸš¨ ìœ íš¨í•œ Rawdata.txt íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []