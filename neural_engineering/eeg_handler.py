import os
import numpy as np
import pandas as pd
from scipy.signal import butter, lfilter
from datetime import datetime

# --- [ê·¸ë˜í”„ ì„¤ì •] ---
import matplotlib
matplotlib.use('Agg') # í™”ë©´ í‘œì‹œ ì—†ì´ íŒŒì¼ ì €ì¥ ì „ìš© ëª¨ë“œ
import matplotlib.pyplot as plt

class SignalProcessor:
    def __init__(self, fs=256):
        self.fs = fs
    def butter_bandpass_filter(self, data, lowcut, highcut, order=2):
        nyq = 0.5 * self.fs
        low = lowcut / nyq
        high = highcut / nyq
        b, a = butter(order, [low, high], btype="band")
        y = lfilter(b, a, data)
        return y
    def get_power(self, data): return data ** 2
    def moving_average(self, data, window_sec=1.0):
        window_size = int(window_sec * self.fs)
        return np.convolve(data, np.ones(window_size)/window_size, mode='same')

def get_latest_rawdata_path(base_path="C:/MAVE_RawData"):
    # 1ìˆœìœ„: Cë“œë¼ì´ë¸Œ ê²½ë¡œ í™•ì¸
    if os.path.exists(base_path):
        try:
            all_folders = [os.path.join(base_path, d) for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]
            if all_folders:
                latest_folder_path = max(all_folders, key=os.path.getctime)
                target_file = os.path.join(latest_folder_path, "Rawdata.txt")
                if os.path.exists(target_file): return target_file
        except: pass
    
    # 2ìˆœìœ„: í”„ë¡œì íŠ¸ í´ë” ë‚´ íŒŒì¼ í™•ì¸
    local_file = "Rawdata.txt"
    if os.path.exists(local_file):
        return os.path.abspath(local_file)
    return None

def calculate_concentration_index(processor, raw_signal):
    epsilon = 1e-10
    theta_wave = processor.butter_bandpass_filter(raw_signal, 4.0, 8.0)
    alpha_wave = processor.butter_bandpass_filter(raw_signal, 8.0, 13.0)
    beta_wave = processor.butter_bandpass_filter(raw_signal, 13.0, 30.0)
    
    theta_power = processor.moving_average(processor.get_power(theta_wave))
    alpha_power = processor.moving_average(processor.get_power(alpha_wave))
    beta_power = processor.moving_average(processor.get_power(beta_wave))
    
    ba_ratio = beta_power / (alpha_power + epsilon)
    bt_ratio = beta_power / (theta_power + epsilon)
    return (ba_ratio + bt_ratio) / 2.0

def save_analysis_log(log_lines):
    try:
        with open("analysis_log.txt", "w", encoding="utf-8") as f:
            f.write("\n".join(log_lines))
    except: pass

# âœ… ìˆ˜ì •ë¨: ì „ì²´ ë°ì´í„°ë¥¼ ë°›ì•„ì„œ Baseline êµ¬ë¶„ì„ ì„ ê·¸ì–´ì£¼ëŠ” í•¨ìˆ˜
def save_z_score_plot(full_z_fp1, full_z_fp2, threshold, ceiling, baseline_sec, fs=256):
    try:
        plt.close('all')
        
        # ì „ì²´ ì‹œê°„ì¶• ìƒì„±
        total_seconds = len(full_z_fp1) / fs
        time_axis = np.linspace(0, total_seconds, len(full_z_fp1))
        
        plt.figure(figsize=(10, 5))
        
        # ì „ì²´ ë°ì´í„° ê·¸ë¦¬ê¸°
        plt.plot(time_axis, full_z_fp1, label='Fp1 Z-Score', color='blue', alpha=0.6, linewidth=1)
        plt.plot(time_axis, full_z_fp2, label='Fp2 Z-Score', color='orange', alpha=0.6, linewidth=1)
        
        # ê¸°ì¤€ì„  ê·¸ë¦¬ê¸°
        plt.axhline(y=threshold, color='green', linestyle='--', label=f'Concentration Threshold ({threshold})')
        
        # âœ… Baseline(30ì´ˆ) êµ¬ë¶„ì„  ì¶”ê°€ (ë¹¨ê°„ ì ì„ )
        plt.axvline(x=baseline_sec, color='red', linestyle=':', linewidth=2, label='End of Baseline (30s)')
        
        # ê·¸ë˜í”„ ê¾¸ë¯¸ê¸°
        plt.title(f"Full Z-Score Flow (Total: {total_seconds:.1f}s)")
        plt.xlabel("Time (seconds)")
        plt.ylabel("Z-Score (rel. to Baseline)")
        plt.legend(loc='upper right')
        plt.grid(True, alpha=0.3)
        plt.ylim(bottom=-2, top=min(ceiling + 1, 10)) # yì¶• ë²”ìœ„ ì•ˆì •í™”

        # ì €ì¥ (ì ˆëŒ€ ê²½ë¡œ)
        current_dir = os.path.dirname(os.path.abspath(__file__))
        project_dir = os.path.dirname(current_dir)
        save_path = os.path.join(project_dir, "z_score_graph.png")
        
        plt.savefig(save_path)
        print(f"ğŸ“Š ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ: {save_path}")
        plt.close()
    except Exception as e:
        print(f"ğŸš¨ ê·¸ë˜í”„ ì €ì¥ ì‹¤íŒ¨: {e}")

def analyze_concentration_intervals(file_path, baseline_sec=30.0, z_threshold=0.7, z_ceiling=4.0):
    log_buffer = []
    print(f"ğŸ” ë¶„ì„ ì‹œì‘: {file_path}")
    
    try:
        try:
            df = pd.read_csv(file_path, delimiter="\t", encoding='cp949')
        except:
            df = pd.read_csv(file_path, delimiter="\t", encoding='utf-8')

        if df.empty: return []

        fs = 256
        processor = SignalProcessor(fs)
        
        col_fp1 = next((c for c in df.columns if 'Fp1' in c), df.columns[1])
        col_fp2 = next((c for c in df.columns if 'Fp2' in c), df.columns[2])

        signal_fp1 = df[col_fp1].values
        signal_fp2 = df[col_fp2].values
        
        # ì „ì²´ ê¸¸ì´ì— ëŒ€í•œ ì§€í‘œ ê³„ì‚°
        idx_fp1 = calculate_concentration_index(processor, signal_fp1)
        idx_fp2 = calculate_concentration_index(processor, signal_fp2)
        
        base_samples = int(baseline_sec * fs)
        
        # ë°ì´í„°ê°€ ë„ˆë¬´ ì§§ì•„ë„ ì¼ë‹¨ ì²˜ë¦¬ëŠ” ì‹œë„
        if len(idx_fp1) <= base_samples:
            print(f"âš ï¸ ê²½ê³ : ë°ì´í„° ê¸¸ì´({len(idx_fp1)/fs:.1f}ì´ˆ)ê°€ Baseline({baseline_sec}ì´ˆ)ë³´ë‹¤ ì§§ìŠµë‹ˆë‹¤.")
            # ì§§ì•„ë„ ì—ëŸ¬ ì•ˆ ë‚˜ê²Œ ê°•ì œ ì„¤ì •
            base_fp1 = idx_fp1
            base_fp2 = idx_fp2
        else:
            base_fp1 = idx_fp1[:base_samples]
            base_fp2 = idx_fp2[:base_samples]
        
        # Z-Score ë³€í™˜
        std_fp1 = np.std(base_fp1) if np.std(base_fp1) > 1e-10 else 1.0
        std_fp2 = np.std(base_fp2) if np.std(base_fp2) > 1e-10 else 1.0
        
        z_fp1 = (idx_fp1 - np.mean(base_fp1)) / std_fp1
        z_fp2 = (idx_fp2 - np.mean(base_fp2)) / std_fp2
        
        # âœ… [í•µì‹¬ ìˆ˜ì • 1] ë¶„ì„ ê²°ê³¼ì™€ ìƒê´€ì—†ì´ ì „ì²´ ê·¸ë˜í”„ë¥¼ ë¬´ì¡°ê±´ ê·¸ë¦¼
        # (ì˜ë¦° ë°ì´í„°ê°€ ì•„ë‹Œ 'z_fp1' ì „ì²´ë¥¼ ë„˜ê¹€)
        save_z_score_plot(z_fp1, z_fp2, z_threshold, z_ceiling, baseline_sec, fs)

        # ì‹¤ì œ ë¶„ì„ (30ì´ˆ ì´í›„ë¶€í„°)
        if len(z_fp1) > base_samples:
            task_z_fp1 = z_fp1[base_samples:]
            task_z_fp2 = z_fp2[base_samples:]
        else:
            print("ğŸ›‘ Baseline ì´í›„ ë°ì´í„°ê°€ ì—†ì–´ êµ¬ê°„ ë¶„ì„ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return []

        # êµ¬ê°„ ê²€ì¶œ ë¡œì§
        is_active = ((task_z_fp1 > z_threshold) | (task_z_fp2 > z_threshold))
        
        intervals = []
        start = None
        
        # iëŠ” task ì‹œì‘ ì‹œì (0ì´ˆ) ê¸°ì¤€ì„. ë‚˜ì¤‘ì— baseline_secë¥¼ ë”í•´ì¤˜ì•¼ ì‹¤ì œ ì‹œê°„.
        for i, active in enumerate(is_active):
            curr_task_time = i / fs
            if active and start is None:
                start = curr_task_time
            elif not active and start is not None:
                if curr_task_time - start >= 3.0: 
                    # ì‹¤ì œ ì˜ìƒ ì‹œê°„ = task ì‹œê°„ + 30ì´ˆ
                    intervals.append((start + baseline_sec, curr_task_time + baseline_sec))
                start = None
                
        if start is not None:
            end_task_time = len(is_active)/fs
            if end_task_time - start >= 3.0:
                 intervals.append((start + baseline_sec, end_task_time + baseline_sec))

        # âœ… [í•µì‹¬ ìˆ˜ì • 2] êµ¬ê°„ì´ ì—†ì–´ë„ ì—ëŸ¬ ë©”ì‹œì§€ ëŒ€ì‹  ë¡œê·¸ë§Œ ë‚¨ê¸°ê³  ì¢…ë£Œ
        if not intervals:
            save_analysis_log(["ì§‘ì¤‘ êµ¬ê°„ ì—†ìŒ (ê·¸ë˜í”„ í™•ì¸ ìš”ë§)"])
            print("ğŸ’¡ ì§‘ì¤‘ êµ¬ê°„ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê·¸ë˜í”„ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì „ì²´ ê¸¸ì´ì˜ ì¼ë¶€ë¥¼ ê°•ì œë¡œ ë°˜í™˜í•˜ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ
            # total_len = len(z_fp1)/fs
            # return [(total_len*0.4, total_len*0.6)] 
            return []

        return intervals

    except Exception as e:
        print(f"ğŸš¨ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return []

def load_timestamp_durations_from_file(file_path=None, ignored=None):
    # ìˆ˜ì •ëœ ë¡œì§: ì¸ìë¡œ ë°›ì€ file_pathê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ìš°ì„  ì‚¬ìš©
    if file_path and os.path.exists(file_path):
        target_path = file_path
    else:
        # ì—†ìœ¼ë©´ ê¸°ì¡´ì²˜ëŸ¼ ìë™ íƒìƒ‰
        target_path = get_latest_rawdata_path()
    
    # ì—¬ê¸°ì„œ ê¸°ì¤€ê°’(Threshold)ì„ ì¡°ì ˆí•˜ì„¸ìš” (í˜„ì¬ 0.7)
    FIXED_THRESHOLD = 0.7 

    if target_path:
        print(f"ğŸ“‚ íŒŒì¼ ë¡œë“œ ë° ë¶„ì„ ì‹œì‘: {target_path}")
        # analyze_concentration_intervals í•¨ìˆ˜ëŠ” ì „ì²´ ê²½ë¡œ(íŒŒì¼ëª… í¬í•¨)ë¥¼ í•„ìš”ë¡œ í•¨
        return analyze_concentration_intervals(target_path, z_threshold=FIXED_THRESHOLD)
    else:
        print("ğŸš¨ ìœ íš¨í•œ Rawdata.txt íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []