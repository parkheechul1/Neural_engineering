import os
import torch
import numpy as np
from moviepy.editor import VideoFileClip
import requests
import json
from dotenv import load_dotenv

from .prompts import SYSTEM_PROMPT

# 1. .env íŒŒì¼ ë¡œë“œ
load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

if not GOOGLE_API_KEY:
    print("ğŸš¨ [ì˜¤ë¥˜] .env íŒŒì¼ì—ì„œ GOOGLE_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
else:
    print(f"ğŸ”‘ API í‚¤ ë¡œë“œ ì„±ê³µ (ì• 5ìë¦¬: {GOOGLE_API_KEY[:5]}...)")

# --- AI ëª¨ë¸ ë¡œë”© (Whisper) ---
try:
    from transformers import pipeline

    device = "cuda:0" if torch.cuda.is_available() else "cpu"
    print(f"ìŒì„± ì¸ì‹(STT) ì¥ì¹˜: {device}")

    stt_pipeline = pipeline(
        "automatic-speech-recognition",
        model="openai/whisper-base", 
        device=device
    )
    print("âœ… Whisper(STT) ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")
    print("âœ… Gemini API ì—°ê²° ì¤€ë¹„ ì™„ë£Œ.")

except Exception as e:
    stt_pipeline = None
    print(f"ğŸš¨ AI ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")

# â–¼â–¼â–¼ [ìˆ˜ì •ëœ ë¶€ë¶„] ì—¬ê¸°ê°€ ì—ëŸ¬ ì›ì¸ì´ì—ˆìŠµë‹ˆë‹¤! â–¼â–¼â–¼
def get_ai_models():
    # ì˜ˆì „ ì½”ë“œ: return stt_pipeline, summarizer_pipeline (X - ì—ëŸ¬ ë°œìƒ)
    # ìˆ˜ì • ì½”ë“œ: return stt_pipeline, "Gemini-API" (O - ì •ìƒ)
    return stt_pipeline, "Gemini-API"
# â–²â–²â–² --------------------------------------- â–²â–²â–²

def find_available_gemini_model():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ìë™ íƒìƒ‰"""
    if not GOOGLE_API_KEY: return None
    url = f"https://generativelanguage.googleapis.com/v1beta/models?key={GOOGLE_API_KEY}"
    try:
        response = requests.get(url)
        if response.status_code == 200:
            models = response.json().get('models', [])
            for m in models:
                if 'generateContent' in m.get('supportedGenerationMethods', []) and 'gemini' in m['name']:
                    if 'flash' in m['name'] or '1.5' in m['name']: return m['name']
            for m in models:
                if 'generateContent' in m.get('supportedGenerationMethods', []) and 'gemini' in m['name']:
                    return m['name']
    except: pass
    return "models/gemini-pro"

def summarize_with_gemini(full_text):
    if not GOOGLE_API_KEY: return "(API í‚¤ ì˜¤ë¥˜)"

    model_name = find_available_gemini_model()
    url = f"https://generativelanguage.googleapis.com/v1beta/{model_name}:generateContent?key={GOOGLE_API_KEY}"
    
    final_prompt = f"{SYSTEM_PROMPT}\n\n[ì…ë ¥ í…ìŠ¤íŠ¸]\n{full_text}"
    payload = {"contents": [{"parts": [{"text": final_prompt}]}]}
    headers = {'Content-Type': 'application/json'}

    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload))
        if response.status_code == 200:
            return response.json()['candidates'][0]['content']['parts'][0]['text'].strip()
        else:
            return f"(API ì—ëŸ¬: {response.status_code})"
    except Exception as e:
        return f"(í†µì‹  ì‹¤íŒ¨: {e})"

def summarize_audio_duration(video_path, start_sec, end_sec):
    if not stt_pipeline: return "STT ëª¨ë¸ ì—†ìŒ", "ìš”ì•½ ë¶ˆê°€"

    try:
        with VideoFileClip(video_path) as video:
            audio_clip = video.subclip(start_sec, end_sec).audio
            audio_array = audio_clip.to_soundarray(fps=16000)
            if audio_array.ndim > 1: audio_array = audio_array.mean(axis=1)
            audio_array = audio_array.astype(np.float32)

        if len(audio_array) == 0: return "(ë¬´ìŒ)", "(ë‚´ìš© ì—†ìŒ)"

        result = stt_pipeline(audio_array, chunk_length_s=30, return_timestamps=False)
        full_text = result['text'].strip()

        if not full_text: return "(ìŒì„± ì—†ìŒ)", "(ë‚´ìš© ì—†ìŒ)"

        if len(full_text) < 5: summary_text = full_text
        else: summary_text = summarize_with_gemini(full_text)

        return full_text, summary_text 

    except Exception as e:
        return f"ì˜¤ë¥˜: {e}", "ì˜¤ë¥˜"